# Surveillance Robot - Assignment 1
**The first ROS-based assignment for the Experimental Robotics Laboratory course held at the [University of Genoa](https://unige.it/it/).**  

---

## Documentation
Click on the following link !!!!!!!ADD LINK!!!!!!!! to visualize the Sphinx documentation regarding the project.

---

## Introduction

This repository contains ROS-based software architecture that simulates a robot used for surveillance purposes.
The robot is placed inside in a known indoor environment. \
The robot's objective is to go around the map, simulating a survaillance task when it gets inside a location.
The program interacts with an ontology to retrieve essential informations to achieve the desired behavior. \
A short video shows the execution of the software architecture:

!!!!!!!!PUT THE VIDEO!!!!!!!!!!!

## How to run

This software is based on ROS Noetic, and it has been developed with this Docker-based
[environment](https://hub.docker.com/repository/docker/carms84/exproblab), which already 
provides the required dependencies. \ 
If the Docker image is not used, it is necesscessary to download some essential packages. If a new version of ROS is installed on your machine, the suggestion is to follow the procedure written in this link: https://github.com/EmaroLab/armor/issues/7. \
Instead, if a older version of ROS is present in your machine, please refer to: https://github.com/EmaroLab/armor. \
In either cases, the procedure explained in the REEDME files should be followed and the needed repositories must be cloned and built in your ROS workspace. \
After Armor has been correctly downloaded and built, the current [repository](https://github.com/FraFerrazzi/exprob_assignment1) of this project must be downloaded and built in a ROS workspace, typing the following command in the terminal:
```bash
cd <absolute path to your ros_workspace>/src
git clone https://github.com/FraFerrazzi/exprob_assignment1.git
cd ..
catkin_make
```
Once the previous commands have been correctly executed it is possible to launch the program. \
Use the following command to launch the software with a keyboard-base interface for the battery level.
```bash
roslaunch exprob_assignemnt1 surveillance_manual.launch
```

Use the following command to launch the software with randomized stimulus for the battery level.
```bash
roslaunch exprob_assignemnt1 surveillance_random.launch
``` 
Two new terminal windows are going to be opened, making a total of three windows opened at the same time. \
One corresponds to the `state_machine.py` GUI that gives a visual feedback of what is happening during the execution of the software architecture. One shows the computations and passages done by the `planner.py` and `controller.py` scripts. The last, shows a user interface regarding the battery state of the controlled by the `robot_battery_state.py` node.

---

## Description

The project consist in creating the software architecture for a naive survaillance robot located inside 
an indoor 2D environment. \
The layout of the environment is randomically generated, but its structure remains the same.
It has 4 rooms, 3 corridors and 7 doors and can be shcmatized by the following image:

<img src="https://github.com/FraFerrazzi/exprob_assignment1/blob/main/diagrams/env-structure.png" width="500">

The difference between a room and a corridor is that a corridor has more than one door allowing the communication with multiple rooms. \
This map is generated by interacting with an ontology defined using the software [Protèjè](https://protege.stanford.edu) and the [Armor](https://github.com/EmaroLab/armor) ontology manager. \
The robot starts in a pre-defined initial location (which is 'E') and waits until the topological map has been correctly initialized and defined. \
Once the map is completed, the robot moves in a new location and waits some time to simulate a 
survaillance task. Once the location has been explored, the robot visits another location. \
When the battery of the robot is low a charging mechanism is implemented.
The charging procedure for the robot is to reach the charging location, which si the 'E' corridor, and simulate a charging task by wasting time in that specific location. \
When the battery is fully charged the robot starts again his defined survaillance behavior. \
When the robot's battery is not low, the robot moves in the environment according to the following 
survaillance policy:
- The robot stays mainly on corridors.
- If a reachable room has not been visited for some time, it becomes urgent and the robot should visit it.

The urgency of a specific location is determined by computing the difference between the last time that the robot has moved and the last time that the same location has been visited.

## Assumptions

For simplicity and showing purposes, we consider a scenario with the following assumptions.
 - The robot moves in a 2D, pre-defined and known environment without obstacles.
 - Rooms have only one door, corridors have at least two doors but one location can only have one door shared with another location.
 - The charging loction is also the initial location of the robot, and it is pre-defined.
 - The number of rooms, corridors and doors is fixed, only the layout changes.
 - The planner node does not implement a real planner. It creates a path composed by randomic via-points. Between the different via-points there is a delay to simulate computation. The planner is used just to waste time.
 - The controller node does not implement a real controller. It does not guide the robot nor make the robot follow the path generated by the planner. As the planner, the controller is used to waste time putting a delay between the via-points of the path.
 - The battery can become low at any time, and the robot should immediately react to this event. The battery low is a signal that does not keep into account the true level of charge of the battery.
 - When a battery low signal comes, all the previous plans and controls are delayed and the reasoning done by the `reasoner()` method is not saved. In this way the robot must reason again before going in the next location.
 - The choice of the next location that will be visited keeps into account only temporal stimulus, excluding data that could come from sensors such as cameras or mircophones.
 - The robot only simulates a survaillance task, so there is not an actual survaillance of the environment.
 - The recharge of the battery does not actually charges a battery but just waste time to simulate the task.
 - The timestamp of the robot and the timestamp of the location which the robot visits are updated when the robot gets in the issued location, so when the `controller()` method has done its execution.
 - When the battery status becomes low, the robot reaches the charging location even if it is not reachable at the moment.

## Limitations

Most of the limitations derive from the hypothesis that were done while implementing the software architecture. \
The fact that the environment is 2D constraint the map to be allocated only on one floor, without the possibility of having stairs or slopes. Also the structure is fixed, so it has a pre-defined number of rooms, corridors and doors. There would be the need to change a bit the code to maintain a reasonable structure for an indoor environment if one of this numbers needs to be changed. \
The planner and the controller as the survaillance task and the charge of the battery are purley done to waste time, giving limitations to the actual tasks that the robot can perform. For example, the robot can not deduce if there is a person in the room or cannot generate a reasonable path to go from one location to another. \
The robot can only check the urgency of adjacent locations that it can reach in a specific time instant, excluding all the locations that are not reachable in the same time instant. \
The robot states that a location is urgent only based on the timeslot for which the issued location has not been visited for, not careing about other possible stimulus.

---

## Software Architecture

The software architecture of the project is further explained in this section. \
First of all the general organization of the repository and the dependencies are pointed out. \
Later on, the general execution of the architecture is discussed with the help of esplicative diagrams.

### Repository Organization

This repository contains a ROS package named `exprob_assignment1` that includes the following resources.
 - [CMakeLists.txt](CMakeLists.txt): File to configure this package.
 - [package.xml](package.xml): File to configure this package.
 - [setup.py](setup.py): File to `import` python modules from the `utilities` folder into the 
   files in the `script` folder. 
 - [launcher/](launcher/): Contains the configuration to launch this package.
    - [surveillance_manual.launch](launcher/surveillance_manual.launch): It launches this package allowing 
       to set manually when the battery state becomes low.
    - [surveillance_random.launch](launcher/surveillance_random.launch): It launches this package with 
      random-based stimulus for the battery status.
 - [msg/](msg/): It contains the message exchanged through ROS topics.
    - [Point.msg](msg/Point.msg): It is the message representing a 2D point.
 - [action/](action/): It contains the definition of each action server used by this software.
    - [Plan.action](action/Plan.action): It defines the target and the current points, the feedback and the results concerning 
      motion planning.
    - [Control.action](action/Control.action): It defines the goal, the feedback and the results 
      concerning motion controlling.
 - [scripts/](scripts/): It contains the implementation of each software components.
    - [state_machine.py](scripts/state_machine.py): It implements the final state machine for the software architecture.
    - [robot_battery_state.py](scripts/robot_battery_state.py): It implements the management of the robot's battery level.
    - [planner.py](scripts/planner.py): It is a dummy implementation of a motion planner.
    - [controller.py](scripts/controller.py): It is a dummy implementation of a motion 
      controller.
 - [utilities/exprob_assignment1](utilities/exprob_assignment1/): It contains auxiliary python files, 
   which are exploited by the files in the `scripts` folder.
    - [architecture_name_mapper.py](utilities/exprob_assignment1/architecture_name_mapper.py): It contains the name 
      of each *node*, *topic*, *server*, *actions* and *parameters* used in this architecture.
    - [state_machine_helper.py](utilities/exprob_assignment1/state_machine_helper.py): It contains the methods called in the 
      [state_machine.py](scripts/state_machine.py) node to make the code easier and cleaner to read.
 - [diagrams/](diagrams/): It contains the diagrams shown below in this README file.
 - [doc/](doc/): It contains the files to visualize the Sphinx documentation.
 - [topological_map/](topological_map/): It contains the Tbox of the ontology used in this software
   architecture. It is also the repository in which the complete ontology is saved for debug purposes.

### Dependencies

The software exploits [roslaunch](http://wiki.ros.org/roslaunch) and 
[rospy](http://wiki.ros.org/rospy) for using python with ROS. Rospy allows defining ROS nodes, 
services and related messages. \
Also, the software uses [actionlib](http://wiki.ros.org/actionlib/DetailedDescription) to define
action servers. In particular, this software is based on the use of the [SimpleActionServer](http://docs.ros.org/en/jade/api/actionlib/html/classactionlib_1_1simple__action__server_1_1SimpleActionServer.html#a2013e3b4a6a3cb0b77bb31403e26f137) and the [SimpleActionClient](https://docs.ros.org/en/api/actionlib/html/classactionlib_1_1simple__action__client_1_1SimpleActionClient.html)
to implement the project. \
The Finite States Machine using the software components provided in this repository is based on [SMACH](http://wiki.ros.org/smach).
It is possible to check the [tutorials](http://wiki.ros.org/smach/Tutorials) related to SMACH, for an overview of its 
functionalities. In addition, it is advised to exploit the [smach_viewer](http://wiki.ros.org/smach_viewer)
node to visualize and debug the implemented Finite States Machine.

## Software Discussion

The software architecure includes four python scripts, which are: `state_machine.py`, `planner.py`, `controller.py`, `robot_battery_state.py`. There is an additional script: `state_machine_helper.py`, which implements all the methods in the `state_machine.py` script. The functioning of the program is explained below, using also some esplicative diagrams such as:
- State diagram.
- Component diagram.
- Sequence diagram.

### State diagram

The first diagram shows the state machine implemented in the code. The figure helps to understand the logic of the project, which is reported below:

<img src="https://github.com/FraFerrazzi/exprob_assignment1/blob/main/diagrams/state_diagram.drawio.png" width="900">

The state machine is composed by seven states, which are:
- `Build World`
- `Reasoner`
- `Planner`
- `Controller`
- `Surveillance`
- `Reach Charge`
- `Charge`

### Component diagram

<img src="https://github.com/buoncubi/arch_skeleton/blob/main/diagrams/planner.png" width="900">

The `planner` node implements an action server named `motion/planner`. This is done by the 
means of the `SimpleActionServer` class based on the `Plan` action message. This action server 
requires the `state/get_pose/` service of the `robot-state` node, and a `target` point given as goal.

Given the current and target points, this component returns a plan as a list of `via_points`, 
which are randomly generated for simplicity. The number of `via_points` can be set with the 
`test/random_plan_points` parameter addressed below. Moreover, each `via_point` is provided 
after a delay to simulate computation, which can be tuned through the `test/random_plan_time` 
parameter. When a new `via_points` is generated, the updated plan is provided as `feedback`. When
all the `via_points` have been generated, the plan is provided as `results`.

While the picture above shows the actual implementation of the action server, you should not 
interact with it through the shown topics directly. Instead, you should use a 
[SimpleActionClient](https://docs.ros.org/en/api/actionlib/html/classactionlib_1_1simple__action__client_1_1SimpleActionClient.html), 
for instance, as:
```python
import actionlib
from arch_skeleton.msg import PlanAction, PlanGoal
...
# Initialize the client and, eventually, wait for the server.
client = actionlib.SimpleActionClient('motion/planner', PlanAction)
client.wait_for_server()
...
def feedback_callback(feedback):
    # Do something when feedback is provided.
    pass  
...
def done_callback(status, results):
    # Do something when results are provided.
    pass  
...
# Send a new `goal`, which is a message of type `PlanGoal`.
client.send_goal(goal, done_cb = done_callback, feedback_cb = feedback_callback)
...
# Get the action server state.
client.get_state()
...
# Cancel all goals (or the current goal only, i.e., `client.cancel_goal()`).
client.cancel_all_goals()
```

To observe the behaviour of the `planner` you can run the following commands.
``` bash
roscore
# Open a new terminal.
rosrun arch_skeleton robot_states.py
# Open a new terminal.
rosservice call /state/set_pose "pose: { x: 0.11,  y: 0.22}"
rosparam set config/environment_size '[10,10]'
rosrun arch_skeleton planner.py
# Open a new terminal.
rosrun actionlib_tools axclient.py /motion/planner
```
Then, a GUI should appear. Set the goal you want to reach and hit the send button. Eventually, you
can cancel the goal as well. Also, you can change the `test/random_plan_points` and 
`test/random_plan_time` parameters (detailed below) to tune the behaviour of the planner.

The last command of the above fragment of code requires the `actionlib-tools` package, which can
be installed done by typing:
```bash
sudo apt update
sudo apt install ros-noetic-actionlib-tools
```


### The `controller` Node, its Message and Parameters

<img src="https://github.com/buoncubi/arch_skeleton/blob/main/diagrams/controller.png" width="900">

The `controller` node implements an action server named `motion/controller`. This is done by 
the means of the `SimpleActionServer` class based on the `Control` action message. This action 
server requires the `state/set_pose/` service of the `robot-state` node and a plan given as a 
list of `via_points` by the `planner`.

Given the plan and the current robot position, this component iterates for each planned 
`via_point` and waits to simulate the time spent moving the robot to that location. The 
waiting time can be tuned through the `test/random_motion_time` parameter detailed below. Each 
time a `via_point` is reached the `state/set_pose` service is invoked, and a `feedback` is 
provided. When the last `via_point` is reached, the action service provides a result by 
propagating the current robot position, which has been already updated through the 
`state/set_pose` service.

Similarly to the `planner` above, instead of using the raw topics, you can rely on a 
`SimpleActionClient`, which should be instantiated as:
```python
client = actionlib.SimpleActionClient('motion/controller', ControlAction)
```
This client would accept goals of type `ControlGoal`.

To observe the behaviour of the `controller` you can run the following commands.
``` bash
roscore
# Open a new terminal.
rosrun arch_skeleton robot_states.py
# Open a new terminal.
rosservice call /state/set_pose "pose: { x: 0.11,  y: 0.22}"
#rosparam set config/environment_size '[10,10]'
rosrun arch_skeleton controller.py
# Open a new terminal.
rosrun actionlib_tools axclient.py /motion/controller
```
Then, the same GUI seen for the `planner` should appear. In this case, you can test goals 
formatted as:
```yaml
via_points: 
  - 
    x: 0.109999999404
    y: 0.219999998808
  - 
    x: 3.61638021469
    y: 5.05489301682
  - 
    x: 0.292526483536
    y: 6.59786701202
  - 
    x: 4.33828830719
    y: 7.73262834549
  - 
    x: 6.0
    y: 6.0
```
You can also change the `test/random_motion_time` parameter (detailed below) to tune
the behaviour of the controller.

### ROS Parameters

This software requires the following ROS parameters.
 
 - `config/environment_size`: It represents the environment boundaries as a list of two float
   numbers, i.e., `[x_max, y_max]`. The environment will have the `x`-th coordinate spanning
   in the interval `[0, x_max)`, while the `y`-th coordinate in `[0, y_max)`.

 - `config/user_pose`: It represents the user's position as a list of two float numbers,
   i.e., `[x, y]`. This pose should be within the `environmet_size`.

 - `config/speech_commands`: It defines the keywords that the user can say to start and end
   the interaction. It must be a list made of two strings (e.g., `["Hello", "Bye"]`) that define
   the keyword to start and end the interaction, respectively.

 - `state/initial_pose`: It represents the initial robot pose as a list of two float numbers, 
   i.e., `[x, y]`. This pose should be within the `environmet_size`.

 - `test/random_plan_points`: It represents the number of via points in a plan, and it should be
   a list of two integer numbers `[min_n, max_n]`. A random value within such an interval will be
   chosen to simulate plans of different lengths.

 - `test/random_plan_time`: It represents the time required to compute the next via point of the 
   plan, and it should be a list of two float numbers, i.e., `[min_time, max_time]` in seconds. 
   A random value within such an interval will be chosen to simulate the time required to 
   compute the next via points.

 - `test/random_motion_time`: It represents the time required to reach the next via point, and 
   it should be a list of two float numbers, i.e., `[min_time, max_time]` in seconds. A random
   value within such an interval will be chosen to simulate the time required to reach the next 
   via points. 

 - `test/random_sense/active`: It is a boolean value that activates (i.e., `True`) or 
   deactivates (`False`) the random-based generation of stimulus (i.e., speech, gesture and 
   battery level). If this parameter is `True`, then the three parameters below are also 
   required.  If it is `False`, then the three parameters below are not used.
 

In addition, the `random_sense.launch` also requires the following three parameters. This 
occurs because `test/random_sense/active` has been set to `True`.

 - `test/random_sense/gesture_time`: It indicates the time passed within two randomly generated 
   pointing gestures. It should be a list of two float numbers, i.e., `[min_time, max_time]` in 
   seconds, and the time passed between gestures will be a random value within such an interval.

 - `test/random_sense/speech_time`: It indicates the time passed within two randomly generated
   commands based on speech. It should be a list of two float numbers, i.e., 
   `[min_time, max_time]` in seconds, and the time passed between speech-based commands will be 
   a random value within such an interval.

 - `test/random_sense/battery_time`: It indicates the time passed within battery state changes 
   (i.e., low/high). It should be a list of two float numbers, i.e., `[min_time, max_time]` in 
   seconds, and the time passed between changes in battery levels will be a random value within 
   such an interval.

---

## Possible Improvements

The improvements regarding this software architecture would be to solve some limitations present in the system, by making more realistic assumptions. \
A list of possible ideas is reported below:
- Put sensors to the robot. In this way it could be possible to make it work on a 3D environment which do not have to be pre-determined. Also, if the robot is equipped with the correct sensors, it could be possible to actually perform a survaillance action, not just simulating it.
- The robot is able to know its position and the position that it needs to reach in the environment. In this way, the `planner()` and the `controller()` methods could actually give a reasonable path to go from the current location to the target location by a set of via-points, and controlling the wheels of the robot in such a way that it follows the desired path.
- Provide a real battery to the robot. In this way it could be possible to actually implement a charging action once the battery is low.
- Create a simulation environment in which the robot can be tested to see the correctess of the algorithms and test its possibilities in different maps, trying also on outdoor environments.

---

## Author
Author: *Francesco Ferrazzi* \
Student ID: *s5262829* \
Email: *s5262829@studenti.unige.it*
